{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPmsG1Z6t9uRcri8Trr4dpB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"x5lGA0Eolo9r","colab_type":"code","colab":{}},"source":["# Mount drive\n","from google.colab import drive \n","drive.mount(\"/content/drive\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"e5bRxh3Yp08P","colab":{}},"source":["# Locate and import files \n","import sys\n","sys.path.append('/content/drive/COMP6248/Reproducibility/')\n","import synthetic\n","import seq2seq\n","import dilate_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rC-RRIygxSKS","colab_type":"code","colab":{}},"source":["# Install missing dependencies\n","!pip install tslearn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"REBCeF0_nGww","colab_type":"code","colab":{}},"source":["import numpy as np\n","import torch\n","from synthetic import create_synthetic_dataset, SyntheticDataset\n","from seq2seq import EncoderRNN, DecoderRNN, Net_GRU\n","from dilate_loss import dilate_loss\n","from torch.utils.data import DataLoader\n","import random\n","from tslearn.metrics import dtw, dtw_path\n","import matplotlib.pyplot as plt\n","import warnings\n","import warnings; warnings.simplefilter('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6CTaDJNhl4gI","colab_type":"code","outputId":"401f7bb8-f573-42ba-ef71-944d64d8497b","executionInfo":{"status":"ok","timestamp":1590582893805,"user_tz":-60,"elapsed":22830,"user":{"displayName":"Virodh Sok One","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0AOZr112LKPhHBR0Sfj02J4R3QGskJ0LW6qkoTw=s64","userId":"01651858088773422787"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Device configuration\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","random.seed(0)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kDL7_Cr3l4s8","colab_type":"code","colab":{}},"source":["# parameters\n","batch_size = 100\n","N = 500\n","N_input = 84\n","N_output = 56  \n","sigma = 0.01\n","gamma = 0.01"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gbJ4XNGT7Reu","colab_type":"code","colab":{}},"source":["import pandas as pd\n","from sklearn import preprocessing\n","\n","train_data = pd.DataFrame(pd.read_csv('/content/drive/My Drive/Colab Notebooks/COMP6248/Reproducibility/ECG5000_TRAIN.tsv',delimiter='\\t',header=None))\n","test_data = pd.DataFrame(pd.read_csv('/content/drive/My Drive/Colab Notebooks/COMP6248/Reproducibility/ECG5000_TEST.tsv',delimiter='\\t',header=None))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nr8bm971aXqP","colab_type":"code","colab":{}},"source":["train_data.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GSmsEmjCCDuu","colab_type":"code","colab":{}},"source":["train_data = train_data.values\n","test_data = test_data.values\n","min_max = preprocessing.MinMaxScaler()\n","train_data = min_max.fit_transform(train_data)\n","test_data = min_max.fit_transform(test_data)\n","train_data = pd.DataFrame(train_data)\n","test_data = pd.DataFrame(test_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GHHksKiLDrJq","colab_type":"code","colab":{}},"source":["train_data.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ifdWD-pRl4x5","colab_type":"code","colab":{}},"source":["# Load synthetic dataset\n","#X_train_input,X_train_target,X_test_input,X_test_target,train_bkp,test_bkp = create_synthetic_dataset(N,N_input,N_output,sigma)\n","X_train_input,X_train_target = train_data.loc[ : , 1:140-55], train_data.loc[ : , 140-55: ]\n","X_test_input,X_test_target = test_data.loc[ : , 1:140-55], test_data.loc[ : , 140-55: ] \n","dataset_train = SyntheticDataset(X_train_input.to_numpy(),X_train_target.to_numpy(),np.zeros(500))\n","dataset_test  = SyntheticDataset(X_test_input.to_numpy(),X_test_target.to_numpy(),np.zeros(4500))\n","trainloader = DataLoader(dataset_train, batch_size=batch_size,shuffle=False, num_workers=1)\n","testloader  = DataLoader(dataset_test, batch_size=batch_size,shuffle=False, num_workers=1)  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Zsqx5Tvs0EE","colab_type":"code","colab":{}},"source":["X_train_input.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K5T6x3ioNRnc","colab_type":"code","colab":{}},"source":["print(type(X_test_input))\n","print(X_test_input.shape,X_test_target.shape,len(trainloader))\n","for i,data in enumerate(trainloader, 0):\n","  inputs, target, _ = data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uyr3PKs_l4z-","colab_type":"code","colab":{}},"source":["def train_model(net,loss_type, learning_rate, epochs=1000, gamma = 0.001,\n","                print_every=50,eval_every=50, verbose=1, Lambda=1, alpha=0.5):\n","    \n","    optimizer = torch.optim.Adam(net.parameters(),lr=learning_rate)\n","    criterion = torch.nn.MSELoss()\n","    \n","    for epoch in range(epochs): \n","        for i, data in enumerate(trainloader, 0):\n","            inputs, target, _ = data\n","            inputs = torch.tensor(inputs, dtype=torch.float32).to(device)\n","            target = torch.tensor(target, dtype=torch.float32).to(device)\n","            batch_size, N_output = target.shape[0:2]                     \n","\n","            # forward + backward + optimize\n","            outputs = net(inputs)\n","            loss_mse,loss_shape,loss_temporal = torch.tensor(0),torch.tensor(0),torch.tensor(0)\n","            \n","            if (loss_type=='mse'):\n","                loss_mse = criterion(target,outputs)\n","                loss = loss_mse                   \n"," \n","            if (loss_type=='dilate'):    \n","                loss, loss_shape, loss_temporal = dilate_loss(target,outputs,0.5, gamma, device)       \n","\n","            if(loss_type=='soft_dtw'):\n","                loss,loss_shape,loss_temporal = dilate_loss(target,outputs,1, gamma, device)    \n","\n","                  \n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()          \n","        \n","        if(verbose):\n","            if (epoch % print_every == 0):\n","                print('epoch ', epoch, ' loss ',loss.item(),' loss shape ',loss_shape.item(),' loss temporal ',loss_temporal.item())\n","                eval_model(net,testloader, gamma,verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r70OFBDJl42T","colab_type":"code","colab":{}},"source":["def eval_model(net,loader, gamma,verbose=1):   \n","    criterion = torch.nn.MSELoss()\n","    losses_mse = []\n","    losses_dtw = []\n","    losses_tdi = []   \n","\n","    for i, data in enumerate(loader, 0):\n","        loss_mse, loss_dtw, loss_tdi = torch.tensor(0),torch.tensor(0),torch.tensor(0)\n","        # get the inputs\n","        inputs, target, breakpoints = data\n","        inputs = torch.tensor(inputs, dtype=torch.float32).to(device)\n","        target = torch.tensor(target, dtype=torch.float32).to(device)\n","        batch_size, N_output = target.shape[0:2]\n","        outputs = net(inputs)\n","         \n","        # MSE    \n","        loss_mse = criterion(target,outputs)    \n","        loss_dtw, loss_tdi = 0,0\n","        # DTW and TDI\n","        for k in range(batch_size):         \n","            target_k_cpu = target[k,:,0:1].view(-1).detach().cpu().numpy()\n","            output_k_cpu = outputs[k,:,0:1].view(-1).detach().cpu().numpy()\n","\n","            loss_dtw += dtw(target_k_cpu,output_k_cpu)\n","            path, sim = dtw_path(target_k_cpu, output_k_cpu)   \n","                       \n","            Dist = 0\n","            for i,j in path:\n","                    Dist += (i-j)*(i-j)\n","            loss_tdi += Dist / (N_output*N_output)            \n","                        \n","        loss_dtw = loss_dtw /batch_size\n","        loss_tdi = loss_tdi / batch_size\n","\n","        # print statistics\n","        losses_mse.append( loss_mse.item() )\n","        losses_dtw.append( loss_dtw )\n","        losses_tdi.append( loss_tdi )\n","\n","    print( ' Eval mse= ', np.array(losses_mse).mean() ,' dtw= ',np.array(losses_dtw).mean() ,' tdi= ', np.array(losses_tdi).mean()) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9RSktwjll44a","colab_type":"code","colab":{}},"source":["\n","encoder = EncoderRNN(input_size=1, hidden_size=128, num_grulstm_layers=1, batch_size=batch_size).to(device)\n","decoder = DecoderRNN(input_size=1, hidden_size=128, num_grulstm_layers=1,fc_units=16, output_size=1).to(device)\n","net_gru_dilate = Net_GRU(encoder,decoder, N_output, device).to(device)\n","train_model(net_gru_dilate,loss_type='dilate',learning_rate=0.001, epochs=1000, gamma=gamma, print_every=50, eval_every=50,verbose=1)\n","\n","encoder = EncoderRNN(input_size=1, hidden_size=128, num_grulstm_layers=1, batch_size=batch_size).to(device)\n","decoder = DecoderRNN(input_size=1, hidden_size=128, num_grulstm_layers=1,fc_units=16, output_size=1).to(device)\n","net_gru_mse = Net_GRU(encoder,decoder, N_output, device).to(device)\n","train_model(net_gru_mse,loss_type='mse',learning_rate=0.001, epochs=1000, gamma=gamma, print_every=50, eval_every=50,verbose=1)\n","\n","encoder = EncoderRNN(input_size=1, hidden_size=128, num_grulstm_layers=1, batch_size=batch_size).to(device)\n","decoder = DecoderRNN(input_size=1, hidden_size=128, num_grulstm_layers=1,fc_units=16, output_size=1).to(device)\n","net_gru_dtw = Net_GRU(encoder,decoder, N_output, device).to(device)\n","train_model(net_gru_dtw,loss_type='soft_dtw',learning_rate=0.001, epochs=1000, gamma=gamma, print_every=50, eval_every=50,verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6RQeE7-4mVCx","colab_type":"code","colab":{}},"source":["# Visualize results\n","gen_test = iter(testloader)\n","test_inputs, test_targets, breaks = next(gen_test)\n","\n","test_inputs  = torch.tensor(test_inputs, dtype=torch.float32).to(device)\n","test_targets = torch.tensor(test_targets, dtype=torch.float32).to(device)\n","criterion = torch.nn.MSELoss()\n","\n","nets = [net_gru_mse,net_gru_dilate,net_gru_dtw]\n","\n","for ind in range(1,51):\n","    plt.figure()\n","    plt.rcParams['figure.figsize'] = (17.0,5.0)  \n","    k = 1\n","    for net in nets:\n","        pred = net(test_inputs).to(device)\n","\n","        input = test_inputs.detach().cpu().numpy()[ind,:,:] \n","        target = test_targets.detach().cpu().numpy()[ind,:,:]\n","        preds = pred.detach().cpu().numpy()[ind,:,:]\n","\n","        plt.subplot(1,3,k)\n","        plt.plot(range(0,N_input +1) ,input,label='input',linewidth=3)\n","        plt.plot(range(N_input-1,N_input+N_output), np.concatenate([ input[N_input-1:N_input], target ]) ,label='target',linewidth=3)   \n","        plt.plot(range(N_input-1,N_input+N_output),  np.concatenate([ input[N_input-1:N_input], preds ])  ,label='prediction',linewidth=3)       \n","        #plt.xticks(range(0,40))\n","        plt.legend()\n","        k = k+1\n","\n","    plt.show()"],"execution_count":0,"outputs":[]}]}